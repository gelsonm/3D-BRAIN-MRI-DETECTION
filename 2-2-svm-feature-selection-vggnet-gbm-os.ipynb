{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-28T12:20:46.089700Z","iopub.execute_input":"2023-03-28T12:20:46.090745Z","iopub.status.idle":"2023-03-28T12:20:46.101690Z","shell.execute_reply.started":"2023-03-28T12:20:46.090707Z","shell.execute_reply":"2023-03-28T12:20:46.100130Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/features/SelectedFeaturesVGGFinalOS.csv\n/kaggle/input/features/FeatureStdVGGFinalTESTOS.csv\n/kaggle/input/features/FeatureStdAlexFinalTESTOS.csv\n/kaggle/input/features/FeatureAvgVGGFinal.csv\n/kaggle/input/features/SelectedFeaturesVGGFinalMergedOS.csv\n/kaggle/input/features/FeatureAvgVGGFinalTESTOS.csv\n/kaggle/input/features/SelectedFeaturesVGGFinal.csv\n/kaggle/input/features/FeatureAvgAlexFinal.csv\n/kaggle/input/features/SelectedFeaturesVGGFinalMerged.csv\n/kaggle/input/features/SelectedFeaturesVGGFinalMergedTESTOS.csv\n/kaggle/input/features/SelectedFeaturesAlexFinalMerged.csv\n/kaggle/input/features/SelectedFeaturesVGGFinalTESTOS.csv\n/kaggle/input/features/FeatureStdVGGFinal.csv\n/kaggle/input/features/FeatureStdVGGFinalOS.csv\n/kaggle/input/features/SelectedFeaturesAlexFinalTESTOS.csv\n/kaggle/input/features/SelectedFeaturesAlexFinal.csv\n/kaggle/input/features/FeatureTargetVGGFinal.csv\n/kaggle/input/features/FeatureAvgVGGTESTOS.csv\n/kaggle/input/features/FeatureTargetAlexFinalOS.csv\n/kaggle/input/features/FeatureAvgVGGFinalOS.csv\n/kaggle/input/features/FeatureID.csv\n/kaggle/input/features/FeatureTargetAlexFinal.csv\n/kaggle/input/features/FeatureTargetVGGFinalTESTOS.csv\n/kaggle/input/features/FeatureAvgAlexFinalTESTOS.csv\n/kaggle/input/features/FeatureTargetVGGFinalOS.csv\n/kaggle/input/features/FeatureStdAlexFinalOS.csv\n/kaggle/input/features/FeatureTargetVGGTESTOS.csv\n/kaggle/input/features/FeatureOS.csv\n/kaggle/input/features/FeatureAvgAlexFinalOS.csv\n/kaggle/input/features/FeatureTargetAlexFinalTESTOS.csv\n/kaggle/input/features/SelectedFeaturesAlexFinalMergedOS.csv\n/kaggle/input/features/test_df.csv\n/kaggle/input/features/SelectedFeaturesFinal.csv\n/kaggle/input/features/SelectedFeaturesAlexFinalOS.csv\n/kaggle/input/features/FeatureStdAlexFinal.csv\n/kaggle/input/features/SelectedFeaturesAlexFinalMergedTESTOS.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_selection import RFE\nfrom sklearn import tree\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.svm import SVC\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:46.103745Z","iopub.execute_input":"2023-03-28T12:20:46.104063Z","iopub.status.idle":"2023-03-28T12:20:53.206567Z","shell.execute_reply.started":"2023-03-28T12:20:46.104036Z","shell.execute_reply":"2023-03-28T12:20:53.205395Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"x_avg = pd.read_csv(\"/kaggle/input/features/FeatureAvgAlexFinalOS.csv\")\nx_std = pd.read_csv(\"/kaggle/input/features/FeatureStdAlexFinalOS.csv\")\ny_train = pd.read_csv(\"/kaggle/input/features/FeatureTargetAlexFinalOS.csv\")\ny = pd.read_csv(\"/kaggle/input/features/FeatureTargetAlexFinalOS.csv\")\ny = y.iloc[:, [1]]\nprint(y['Survival_binary'].dtype)\n\ntest_df = pd.read_csv(\"/kaggle/input/features/test_df.csv\")\n\n\ny_train = y_train.iloc[:, [1]]\n\nx_avg_test = pd.read_csv(\"/kaggle/input/features/FeatureAvgAlexFinalTESTOS.csv\")\nx_std_test = pd.read_csv(\"/kaggle/input/features/FeatureStdAlexFinalTESTOS.csv\")\ny_train_test = pd.read_csv(\"/kaggle/input/features/FeatureTargetAlexFinalTESTOS.csv\")\n\n\ny_train_test = y_train_test.iloc[:, [1]]\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:53.207928Z","iopub.execute_input":"2023-03-28T12:20:53.208541Z","iopub.status.idle":"2023-03-28T12:20:53.647619Z","shell.execute_reply.started":"2023-03-28T12:20:53.208500Z","shell.execute_reply":"2023-03-28T12:20:53.646178Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"int64\n","output_type":"stream"}]},{"cell_type":"code","source":"x_avg.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:53.649953Z","iopub.execute_input":"2023-03-28T12:20:53.650294Z","iopub.status.idle":"2023-03-28T12:20:53.684668Z","shell.execute_reply.started":"2023-03-28T12:20:53.650264Z","shell.execute_reply":"2023-03-28T12:20:53.683407Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   AlexNet_Avg_F0  AlexNet_Avg_F1  AlexNet_Avg_F2  AlexNet_Avg_F3  \\\n0        0.000374        0.042427        0.066797        0.007308   \n1        0.001945        0.041329        0.078117        0.000885   \n2        0.002961        0.036976        0.144324        0.006022   \n3        0.002229        0.023280        0.039875        0.020544   \n4        0.001826        0.022827        0.017068        0.002691   \n\n   AlexNet_Avg_F4  AlexNet_Avg_F5  AlexNet_Avg_F6  AlexNet_Avg_F7  \\\n0        0.000046        0.084987        1.259873        0.031055   \n1        0.000154        0.099475        1.353625        0.010629   \n2        0.006292        0.223103        2.224358        0.015679   \n3        0.000184        0.067871        1.726983        0.029223   \n4        0.001559        0.107797        1.147238        0.028763   \n\n   AlexNet_Avg_F8  AlexNet_Avg_F9  ...  AlexNet_Avg_F246  AlexNet_Avg_F247  \\\n0        0.000751        0.096842  ...          0.000917          0.002009   \n1        0.006738        0.250591  ...          0.001235          0.001135   \n2        0.035390        0.051285  ...          0.000637          0.009502   \n3        0.007647        0.078217  ...          0.002807          0.021293   \n4        0.000003        0.147898  ...          0.000882          0.006140   \n\n   AlexNet_Avg_F248  AlexNet_Avg_F249  AlexNet_Avg_F250  AlexNet_Avg_F251  \\\n0          0.400057          0.054643          0.105998          0.940495   \n1          0.955365          0.024682          0.072329          0.359375   \n2          0.534150          0.076820          0.116177          0.732095   \n3          0.586790          0.019140          0.073723          0.516912   \n4          0.636418          0.057201          0.005395          0.262437   \n\n   AlexNet_Avg_F252  AlexNet_Avg_F253  AlexNet_Avg_F254  AlexNet_Avg_F255  \n0          0.042096          0.592592          0.076810          0.042103  \n1          0.081209          0.578653          0.062131          0.073096  \n2          0.068831          0.624203          0.119198          0.049052  \n3          0.029411          0.625935          0.074210          0.040071  \n4          0.063906          0.750830          0.029361          0.033264  \n\n[5 rows x 256 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AlexNet_Avg_F0</th>\n      <th>AlexNet_Avg_F1</th>\n      <th>AlexNet_Avg_F2</th>\n      <th>AlexNet_Avg_F3</th>\n      <th>AlexNet_Avg_F4</th>\n      <th>AlexNet_Avg_F5</th>\n      <th>AlexNet_Avg_F6</th>\n      <th>AlexNet_Avg_F7</th>\n      <th>AlexNet_Avg_F8</th>\n      <th>AlexNet_Avg_F9</th>\n      <th>...</th>\n      <th>AlexNet_Avg_F246</th>\n      <th>AlexNet_Avg_F247</th>\n      <th>AlexNet_Avg_F248</th>\n      <th>AlexNet_Avg_F249</th>\n      <th>AlexNet_Avg_F250</th>\n      <th>AlexNet_Avg_F251</th>\n      <th>AlexNet_Avg_F252</th>\n      <th>AlexNet_Avg_F253</th>\n      <th>AlexNet_Avg_F254</th>\n      <th>AlexNet_Avg_F255</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000374</td>\n      <td>0.042427</td>\n      <td>0.066797</td>\n      <td>0.007308</td>\n      <td>0.000046</td>\n      <td>0.084987</td>\n      <td>1.259873</td>\n      <td>0.031055</td>\n      <td>0.000751</td>\n      <td>0.096842</td>\n      <td>...</td>\n      <td>0.000917</td>\n      <td>0.002009</td>\n      <td>0.400057</td>\n      <td>0.054643</td>\n      <td>0.105998</td>\n      <td>0.940495</td>\n      <td>0.042096</td>\n      <td>0.592592</td>\n      <td>0.076810</td>\n      <td>0.042103</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001945</td>\n      <td>0.041329</td>\n      <td>0.078117</td>\n      <td>0.000885</td>\n      <td>0.000154</td>\n      <td>0.099475</td>\n      <td>1.353625</td>\n      <td>0.010629</td>\n      <td>0.006738</td>\n      <td>0.250591</td>\n      <td>...</td>\n      <td>0.001235</td>\n      <td>0.001135</td>\n      <td>0.955365</td>\n      <td>0.024682</td>\n      <td>0.072329</td>\n      <td>0.359375</td>\n      <td>0.081209</td>\n      <td>0.578653</td>\n      <td>0.062131</td>\n      <td>0.073096</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.002961</td>\n      <td>0.036976</td>\n      <td>0.144324</td>\n      <td>0.006022</td>\n      <td>0.006292</td>\n      <td>0.223103</td>\n      <td>2.224358</td>\n      <td>0.015679</td>\n      <td>0.035390</td>\n      <td>0.051285</td>\n      <td>...</td>\n      <td>0.000637</td>\n      <td>0.009502</td>\n      <td>0.534150</td>\n      <td>0.076820</td>\n      <td>0.116177</td>\n      <td>0.732095</td>\n      <td>0.068831</td>\n      <td>0.624203</td>\n      <td>0.119198</td>\n      <td>0.049052</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.002229</td>\n      <td>0.023280</td>\n      <td>0.039875</td>\n      <td>0.020544</td>\n      <td>0.000184</td>\n      <td>0.067871</td>\n      <td>1.726983</td>\n      <td>0.029223</td>\n      <td>0.007647</td>\n      <td>0.078217</td>\n      <td>...</td>\n      <td>0.002807</td>\n      <td>0.021293</td>\n      <td>0.586790</td>\n      <td>0.019140</td>\n      <td>0.073723</td>\n      <td>0.516912</td>\n      <td>0.029411</td>\n      <td>0.625935</td>\n      <td>0.074210</td>\n      <td>0.040071</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001826</td>\n      <td>0.022827</td>\n      <td>0.017068</td>\n      <td>0.002691</td>\n      <td>0.001559</td>\n      <td>0.107797</td>\n      <td>1.147238</td>\n      <td>0.028763</td>\n      <td>0.000003</td>\n      <td>0.147898</td>\n      <td>...</td>\n      <td>0.000882</td>\n      <td>0.006140</td>\n      <td>0.636418</td>\n      <td>0.057201</td>\n      <td>0.005395</td>\n      <td>0.262437</td>\n      <td>0.063906</td>\n      <td>0.750830</td>\n      <td>0.029361</td>\n      <td>0.033264</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 256 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x_std.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:53.686678Z","iopub.execute_input":"2023-03-28T12:20:53.687120Z","iopub.status.idle":"2023-03-28T12:20:53.712034Z","shell.execute_reply.started":"2023-03-28T12:20:53.687078Z","shell.execute_reply":"2023-03-28T12:20:53.711074Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   AlexNet_Std_F0  AlexNet_Std_F1  AlexNet_Std_F2  AlexNet_Std_F3  \\\n0        0.002128        0.060166        0.094494        0.013708   \n1        0.008416        0.059405        0.109643        0.006171   \n2        0.009969        0.047950        0.149918        0.014066   \n3        0.010240        0.030216        0.065348        0.034549   \n4        0.005900        0.029142        0.052758        0.004949   \n\n   AlexNet_Std_F4  AlexNet_Std_F5  AlexNet_Std_F6  AlexNet_Std_F7  \\\n0        0.000397        0.042453        0.361317        0.047386   \n1        0.000942        0.067850        0.385692        0.032134   \n2        0.010206        0.181994        0.253982        0.017966   \n3        0.001048        0.053437        0.371911        0.043961   \n4        0.004888        0.100951        0.263424        0.038265   \n\n   AlexNet_Std_F8  AlexNet_Std_F9  ...  AlexNet_Std_F246  AlexNet_Std_F247  \\\n0        0.002522        0.092039  ...          0.003381          0.004940   \n1        0.015041        0.118155  ...          0.006092          0.006788   \n2        0.049651        0.059949  ...          0.003700          0.016842   \n3        0.015041        0.068596  ...          0.010356          0.020193   \n4        0.000020        0.144775  ...          0.003878          0.009201   \n\n   AlexNet_Std_F248  AlexNet_Std_F249  AlexNet_Std_F250  AlexNet_Std_F251  \\\n0          0.259386          0.082711          0.057867          0.270276   \n1          0.667349          0.028850          0.060325          0.204344   \n2          0.260538          0.071717          0.110564          0.425334   \n3          0.282370          0.020016          0.070781          0.264353   \n4          0.435877          0.049857          0.009594          0.170952   \n\n   AlexNet_Std_F252  AlexNet_Std_F253  AlexNet_Std_F254  AlexNet_Std_F255  \n0          0.037434          0.147936          0.086578          0.070345  \n1          0.084894          0.182870          0.076749          0.128031  \n2          0.075467          0.153674          0.153151          0.079805  \n3          0.041177          0.204733          0.107178          0.048623  \n4          0.040667          0.260383          0.059850          0.038089  \n\n[5 rows x 256 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AlexNet_Std_F0</th>\n      <th>AlexNet_Std_F1</th>\n      <th>AlexNet_Std_F2</th>\n      <th>AlexNet_Std_F3</th>\n      <th>AlexNet_Std_F4</th>\n      <th>AlexNet_Std_F5</th>\n      <th>AlexNet_Std_F6</th>\n      <th>AlexNet_Std_F7</th>\n      <th>AlexNet_Std_F8</th>\n      <th>AlexNet_Std_F9</th>\n      <th>...</th>\n      <th>AlexNet_Std_F246</th>\n      <th>AlexNet_Std_F247</th>\n      <th>AlexNet_Std_F248</th>\n      <th>AlexNet_Std_F249</th>\n      <th>AlexNet_Std_F250</th>\n      <th>AlexNet_Std_F251</th>\n      <th>AlexNet_Std_F252</th>\n      <th>AlexNet_Std_F253</th>\n      <th>AlexNet_Std_F254</th>\n      <th>AlexNet_Std_F255</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.002128</td>\n      <td>0.060166</td>\n      <td>0.094494</td>\n      <td>0.013708</td>\n      <td>0.000397</td>\n      <td>0.042453</td>\n      <td>0.361317</td>\n      <td>0.047386</td>\n      <td>0.002522</td>\n      <td>0.092039</td>\n      <td>...</td>\n      <td>0.003381</td>\n      <td>0.004940</td>\n      <td>0.259386</td>\n      <td>0.082711</td>\n      <td>0.057867</td>\n      <td>0.270276</td>\n      <td>0.037434</td>\n      <td>0.147936</td>\n      <td>0.086578</td>\n      <td>0.070345</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.008416</td>\n      <td>0.059405</td>\n      <td>0.109643</td>\n      <td>0.006171</td>\n      <td>0.000942</td>\n      <td>0.067850</td>\n      <td>0.385692</td>\n      <td>0.032134</td>\n      <td>0.015041</td>\n      <td>0.118155</td>\n      <td>...</td>\n      <td>0.006092</td>\n      <td>0.006788</td>\n      <td>0.667349</td>\n      <td>0.028850</td>\n      <td>0.060325</td>\n      <td>0.204344</td>\n      <td>0.084894</td>\n      <td>0.182870</td>\n      <td>0.076749</td>\n      <td>0.128031</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.009969</td>\n      <td>0.047950</td>\n      <td>0.149918</td>\n      <td>0.014066</td>\n      <td>0.010206</td>\n      <td>0.181994</td>\n      <td>0.253982</td>\n      <td>0.017966</td>\n      <td>0.049651</td>\n      <td>0.059949</td>\n      <td>...</td>\n      <td>0.003700</td>\n      <td>0.016842</td>\n      <td>0.260538</td>\n      <td>0.071717</td>\n      <td>0.110564</td>\n      <td>0.425334</td>\n      <td>0.075467</td>\n      <td>0.153674</td>\n      <td>0.153151</td>\n      <td>0.079805</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.010240</td>\n      <td>0.030216</td>\n      <td>0.065348</td>\n      <td>0.034549</td>\n      <td>0.001048</td>\n      <td>0.053437</td>\n      <td>0.371911</td>\n      <td>0.043961</td>\n      <td>0.015041</td>\n      <td>0.068596</td>\n      <td>...</td>\n      <td>0.010356</td>\n      <td>0.020193</td>\n      <td>0.282370</td>\n      <td>0.020016</td>\n      <td>0.070781</td>\n      <td>0.264353</td>\n      <td>0.041177</td>\n      <td>0.204733</td>\n      <td>0.107178</td>\n      <td>0.048623</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.005900</td>\n      <td>0.029142</td>\n      <td>0.052758</td>\n      <td>0.004949</td>\n      <td>0.004888</td>\n      <td>0.100951</td>\n      <td>0.263424</td>\n      <td>0.038265</td>\n      <td>0.000020</td>\n      <td>0.144775</td>\n      <td>...</td>\n      <td>0.003878</td>\n      <td>0.009201</td>\n      <td>0.435877</td>\n      <td>0.049857</td>\n      <td>0.009594</td>\n      <td>0.170952</td>\n      <td>0.040667</td>\n      <td>0.260383</td>\n      <td>0.059850</td>\n      <td>0.038089</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 256 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler_avg = StandardScaler()\nscaler_std = StandardScaler()\nscaler_avg_test = StandardScaler()\nscaler_std_test = StandardScaler()\n\nscaler_avg.fit(x_avg.values)\nscaler_std.fit(x_std.values)\n\nscaler_avg_test.fit(x_avg_test.values)\nscaler_std_test.fit(x_std_test.values)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:53.713077Z","iopub.execute_input":"2023-03-28T12:20:53.714027Z","iopub.status.idle":"2023-03-28T12:20:53.735472Z","shell.execute_reply.started":"2023-03-28T12:20:53.713993Z","shell.execute_reply":"2023-03-28T12:20:53.734395Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"StandardScaler()"},"metadata":{}}]},{"cell_type":"code","source":"len(scaler_avg.mean_)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:53.736843Z","iopub.execute_input":"2023-03-28T12:20:53.737171Z","iopub.status.idle":"2023-03-28T12:20:53.743908Z","shell.execute_reply.started":"2023-03-28T12:20:53.737142Z","shell.execute_reply":"2023-03-28T12:20:53.742948Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"256"},"metadata":{}}]},{"cell_type":"code","source":"# scaler.transform(x_train)\nx_avg = pd.DataFrame(scaler_avg.transform(x_avg.values), columns=x_avg.columns, index=x_avg.index)\nx_std = pd.DataFrame(scaler_std.transform(x_std.values), columns=x_std.columns, index=x_std.index)\n\nx_avg_test = pd.DataFrame(scaler_avg_test.transform(x_avg_test.values), columns=x_avg_test.columns, index=x_avg_test.index)\nx_std_test = pd.DataFrame(scaler_std_test.transform(x_std_test.values), columns=x_std_test.columns, index=x_std_test.index)\n\nx_avg.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:53.745204Z","iopub.execute_input":"2023-03-28T12:20:53.746433Z","iopub.status.idle":"2023-03-28T12:20:53.786563Z","shell.execute_reply.started":"2023-03-28T12:20:53.746393Z","shell.execute_reply":"2023-03-28T12:20:53.785601Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   AlexNet_Avg_F0  AlexNet_Avg_F1  AlexNet_Avg_F2  AlexNet_Avg_F3  \\\n0       -0.454000       -0.230860        0.137106       -0.448268   \n1       -0.034004       -0.253034        0.359772       -0.795182   \n2        0.237575       -0.340875        1.662070       -0.517723   \n3        0.042016       -0.617266       -0.392451        0.266700   \n4       -0.065692       -0.626424       -0.841074       -0.697612   \n\n   AlexNet_Avg_F4  AlexNet_Avg_F5  AlexNet_Avg_F6  AlexNet_Avg_F7  \\\n0       -0.383218        0.098718        0.451090        1.014045   \n1       -0.351884        0.349578        0.697259       -0.186531   \n2        1.443260        2.490196        2.983567        0.110323   \n3       -0.343064       -0.197647        1.677595        0.906423   \n4        0.059214        0.493681        0.155343        0.879378   \n\n   AlexNet_Avg_F8  AlexNet_Avg_F9  ...  AlexNet_Avg_F246  AlexNet_Avg_F247  \\\n0       -0.760153       -0.551023  ...         -0.466738         -0.538662   \n1       -0.195385        0.240394  ...         -0.424767         -0.635401   \n2        2.507372       -0.785529  ...         -0.503645          0.290303   \n3       -0.109706       -0.646897  ...         -0.217270          1.594655   \n4       -0.830755       -0.288218  ...         -0.471295         -0.081685   \n\n   AlexNet_Avg_F248  AlexNet_Avg_F249  AlexNet_Avg_F250  AlexNet_Avg_F251  \\\n0         -0.553123         -0.732165          1.085499          3.957331   \n1          1.267340         -1.291878          0.392188          0.494354   \n2         -0.113526         -0.317874          1.295093          2.715446   \n3          0.059043         -1.395404          0.420896          1.433144   \n4          0.221737         -0.684369         -0.986075         -0.083308   \n\n   AlexNet_Avg_F252  AlexNet_Avg_F253  AlexNet_Avg_F254  AlexNet_Avg_F255  \n0         -0.381331          0.017719          0.074146         -0.105789  \n1          0.530243         -0.047625         -0.190926          0.512620  \n2          0.241753          0.165911          0.839588          0.032864  \n3         -0.676982          0.174030          0.027187         -0.146343  \n4          0.126970          0.759535         -0.782681         -0.282165  \n\n[5 rows x 256 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AlexNet_Avg_F0</th>\n      <th>AlexNet_Avg_F1</th>\n      <th>AlexNet_Avg_F2</th>\n      <th>AlexNet_Avg_F3</th>\n      <th>AlexNet_Avg_F4</th>\n      <th>AlexNet_Avg_F5</th>\n      <th>AlexNet_Avg_F6</th>\n      <th>AlexNet_Avg_F7</th>\n      <th>AlexNet_Avg_F8</th>\n      <th>AlexNet_Avg_F9</th>\n      <th>...</th>\n      <th>AlexNet_Avg_F246</th>\n      <th>AlexNet_Avg_F247</th>\n      <th>AlexNet_Avg_F248</th>\n      <th>AlexNet_Avg_F249</th>\n      <th>AlexNet_Avg_F250</th>\n      <th>AlexNet_Avg_F251</th>\n      <th>AlexNet_Avg_F252</th>\n      <th>AlexNet_Avg_F253</th>\n      <th>AlexNet_Avg_F254</th>\n      <th>AlexNet_Avg_F255</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.454000</td>\n      <td>-0.230860</td>\n      <td>0.137106</td>\n      <td>-0.448268</td>\n      <td>-0.383218</td>\n      <td>0.098718</td>\n      <td>0.451090</td>\n      <td>1.014045</td>\n      <td>-0.760153</td>\n      <td>-0.551023</td>\n      <td>...</td>\n      <td>-0.466738</td>\n      <td>-0.538662</td>\n      <td>-0.553123</td>\n      <td>-0.732165</td>\n      <td>1.085499</td>\n      <td>3.957331</td>\n      <td>-0.381331</td>\n      <td>0.017719</td>\n      <td>0.074146</td>\n      <td>-0.105789</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.034004</td>\n      <td>-0.253034</td>\n      <td>0.359772</td>\n      <td>-0.795182</td>\n      <td>-0.351884</td>\n      <td>0.349578</td>\n      <td>0.697259</td>\n      <td>-0.186531</td>\n      <td>-0.195385</td>\n      <td>0.240394</td>\n      <td>...</td>\n      <td>-0.424767</td>\n      <td>-0.635401</td>\n      <td>1.267340</td>\n      <td>-1.291878</td>\n      <td>0.392188</td>\n      <td>0.494354</td>\n      <td>0.530243</td>\n      <td>-0.047625</td>\n      <td>-0.190926</td>\n      <td>0.512620</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.237575</td>\n      <td>-0.340875</td>\n      <td>1.662070</td>\n      <td>-0.517723</td>\n      <td>1.443260</td>\n      <td>2.490196</td>\n      <td>2.983567</td>\n      <td>0.110323</td>\n      <td>2.507372</td>\n      <td>-0.785529</td>\n      <td>...</td>\n      <td>-0.503645</td>\n      <td>0.290303</td>\n      <td>-0.113526</td>\n      <td>-0.317874</td>\n      <td>1.295093</td>\n      <td>2.715446</td>\n      <td>0.241753</td>\n      <td>0.165911</td>\n      <td>0.839588</td>\n      <td>0.032864</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.042016</td>\n      <td>-0.617266</td>\n      <td>-0.392451</td>\n      <td>0.266700</td>\n      <td>-0.343064</td>\n      <td>-0.197647</td>\n      <td>1.677595</td>\n      <td>0.906423</td>\n      <td>-0.109706</td>\n      <td>-0.646897</td>\n      <td>...</td>\n      <td>-0.217270</td>\n      <td>1.594655</td>\n      <td>0.059043</td>\n      <td>-1.395404</td>\n      <td>0.420896</td>\n      <td>1.433144</td>\n      <td>-0.676982</td>\n      <td>0.174030</td>\n      <td>0.027187</td>\n      <td>-0.146343</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.065692</td>\n      <td>-0.626424</td>\n      <td>-0.841074</td>\n      <td>-0.697612</td>\n      <td>0.059214</td>\n      <td>0.493681</td>\n      <td>0.155343</td>\n      <td>0.879378</td>\n      <td>-0.830755</td>\n      <td>-0.288218</td>\n      <td>...</td>\n      <td>-0.471295</td>\n      <td>-0.081685</td>\n      <td>0.221737</td>\n      <td>-0.684369</td>\n      <td>-0.986075</td>\n      <td>-0.083308</td>\n      <td>0.126970</td>\n      <td>0.759535</td>\n      <td>-0.782681</td>\n      <td>-0.282165</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 256 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x_std.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:53.787849Z","iopub.execute_input":"2023-03-28T12:20:53.788172Z","iopub.status.idle":"2023-03-28T12:20:53.814677Z","shell.execute_reply.started":"2023-03-28T12:20:53.788143Z","shell.execute_reply":"2023-03-28T12:20:53.813147Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   AlexNet_Std_F0  AlexNet_Std_F1  AlexNet_Std_F2  AlexNet_Std_F3  \\\n0       -0.444693        0.255770        0.833118       -0.260932   \n1        0.426953        0.232367        1.214500       -0.758980   \n2        0.642127       -0.120069        2.228477       -0.237269   \n3        0.679728       -0.665647        0.099323        1.116386   \n4        0.078104       -0.698706       -0.217656       -0.839780   \n\n   AlexNet_Std_F4  AlexNet_Std_F5  AlexNet_Std_F6  AlexNet_Std_F7  \\\n0       -0.497431       -0.389095        1.082699        1.527090   \n1       -0.390603        0.266940        1.368716        0.706573   \n2        1.424860        3.215457       -0.176784       -0.055615   \n3       -0.369824       -0.105354        1.207016        1.342814   \n4        0.382576        1.121992       -0.065996        1.036415   \n\n   AlexNet_Std_F8  AlexNet_Std_F9  ...  AlexNet_Std_F246  AlexNet_Std_F247  \\\n0       -0.977587       -0.137129  ...         -0.519961         -0.622030   \n1        0.109306        0.276647  ...         -0.276371         -0.438989   \n2        3.114311       -0.645575  ...         -0.491272          0.556564   \n3        0.109326       -0.508568  ...          0.106795          0.888383   \n4       -1.194798        0.698430  ...         -0.475296         -0.200069   \n\n   AlexNet_Std_F248  AlexNet_Std_F249  AlexNet_Std_F250  AlexNet_Std_F251  \\\n0          0.107081          1.201201          0.719765          1.338294   \n1          3.513845         -1.012400          0.813587          0.557395   \n2          0.116700          0.749354          2.731747          3.174790   \n3          0.299015         -1.375477          1.212803          1.268137   \n4          1.580899         -0.149069         -1.123315          0.161897   \n\n   AlexNet_Std_F252  AlexNet_Std_F253  AlexNet_Std_F254  AlexNet_Std_F255  \n0         -0.379619         -0.555503          0.376345          0.409671  \n1          1.191488          0.077160          0.150569          1.785368  \n2          0.879429         -0.451589          1.905600          0.635267  \n3         -0.255695          0.473118          0.849552         -0.108354  \n4         -0.272602          1.480946         -0.237614         -0.359575  \n\n[5 rows x 256 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AlexNet_Std_F0</th>\n      <th>AlexNet_Std_F1</th>\n      <th>AlexNet_Std_F2</th>\n      <th>AlexNet_Std_F3</th>\n      <th>AlexNet_Std_F4</th>\n      <th>AlexNet_Std_F5</th>\n      <th>AlexNet_Std_F6</th>\n      <th>AlexNet_Std_F7</th>\n      <th>AlexNet_Std_F8</th>\n      <th>AlexNet_Std_F9</th>\n      <th>...</th>\n      <th>AlexNet_Std_F246</th>\n      <th>AlexNet_Std_F247</th>\n      <th>AlexNet_Std_F248</th>\n      <th>AlexNet_Std_F249</th>\n      <th>AlexNet_Std_F250</th>\n      <th>AlexNet_Std_F251</th>\n      <th>AlexNet_Std_F252</th>\n      <th>AlexNet_Std_F253</th>\n      <th>AlexNet_Std_F254</th>\n      <th>AlexNet_Std_F255</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.444693</td>\n      <td>0.255770</td>\n      <td>0.833118</td>\n      <td>-0.260932</td>\n      <td>-0.497431</td>\n      <td>-0.389095</td>\n      <td>1.082699</td>\n      <td>1.527090</td>\n      <td>-0.977587</td>\n      <td>-0.137129</td>\n      <td>...</td>\n      <td>-0.519961</td>\n      <td>-0.622030</td>\n      <td>0.107081</td>\n      <td>1.201201</td>\n      <td>0.719765</td>\n      <td>1.338294</td>\n      <td>-0.379619</td>\n      <td>-0.555503</td>\n      <td>0.376345</td>\n      <td>0.409671</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.426953</td>\n      <td>0.232367</td>\n      <td>1.214500</td>\n      <td>-0.758980</td>\n      <td>-0.390603</td>\n      <td>0.266940</td>\n      <td>1.368716</td>\n      <td>0.706573</td>\n      <td>0.109306</td>\n      <td>0.276647</td>\n      <td>...</td>\n      <td>-0.276371</td>\n      <td>-0.438989</td>\n      <td>3.513845</td>\n      <td>-1.012400</td>\n      <td>0.813587</td>\n      <td>0.557395</td>\n      <td>1.191488</td>\n      <td>0.077160</td>\n      <td>0.150569</td>\n      <td>1.785368</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.642127</td>\n      <td>-0.120069</td>\n      <td>2.228477</td>\n      <td>-0.237269</td>\n      <td>1.424860</td>\n      <td>3.215457</td>\n      <td>-0.176784</td>\n      <td>-0.055615</td>\n      <td>3.114311</td>\n      <td>-0.645575</td>\n      <td>...</td>\n      <td>-0.491272</td>\n      <td>0.556564</td>\n      <td>0.116700</td>\n      <td>0.749354</td>\n      <td>2.731747</td>\n      <td>3.174790</td>\n      <td>0.879429</td>\n      <td>-0.451589</td>\n      <td>1.905600</td>\n      <td>0.635267</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.679728</td>\n      <td>-0.665647</td>\n      <td>0.099323</td>\n      <td>1.116386</td>\n      <td>-0.369824</td>\n      <td>-0.105354</td>\n      <td>1.207016</td>\n      <td>1.342814</td>\n      <td>0.109326</td>\n      <td>-0.508568</td>\n      <td>...</td>\n      <td>0.106795</td>\n      <td>0.888383</td>\n      <td>0.299015</td>\n      <td>-1.375477</td>\n      <td>1.212803</td>\n      <td>1.268137</td>\n      <td>-0.255695</td>\n      <td>0.473118</td>\n      <td>0.849552</td>\n      <td>-0.108354</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.078104</td>\n      <td>-0.698706</td>\n      <td>-0.217656</td>\n      <td>-0.839780</td>\n      <td>0.382576</td>\n      <td>1.121992</td>\n      <td>-0.065996</td>\n      <td>1.036415</td>\n      <td>-1.194798</td>\n      <td>0.698430</td>\n      <td>...</td>\n      <td>-0.475296</td>\n      <td>-0.200069</td>\n      <td>1.580899</td>\n      <td>-0.149069</td>\n      <td>-1.123315</td>\n      <td>0.161897</td>\n      <td>-0.272602</td>\n      <td>1.480946</td>\n      <td>-0.237614</td>\n      <td>-0.359575</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 256 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x_train = x_avg.join(x_std)\nx_train_test = x_avg_test.join(x_std_test)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:53.818705Z","iopub.execute_input":"2023-03-28T12:20:53.819055Z","iopub.status.idle":"2023-03-28T12:20:53.840815Z","shell.execute_reply.started":"2023-03-28T12:20:53.819024Z","shell.execute_reply":"2023-03-28T12:20:53.839550Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"x_train.shape,y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:53.842391Z","iopub.execute_input":"2023-03-28T12:20:53.842750Z","iopub.status.idle":"2023-03-28T12:20:53.852999Z","shell.execute_reply.started":"2023-03-28T12:20:53.842718Z","shell.execute_reply":"2023-03-28T12:20:53.851716Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"((1596, 512), (1596, 1))"},"metadata":{}}]},{"cell_type":"code","source":"corr_matrix = x_train.corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\nto_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\nx_train.drop(to_drop, axis=1, inplace=True)\nx_train_test.drop(to_drop, axis=1, inplace=True)\n\nx_train.shape,x_train_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:53.854715Z","iopub.execute_input":"2023-03-28T12:20:53.855070Z","iopub.status.idle":"2023-03-28T12:20:55.287256Z","shell.execute_reply.started":"2023-03-28T12:20:53.855039Z","shell.execute_reply":"2023-03-28T12:20:55.286048Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"((1596, 342), (200, 342))"},"metadata":{}}]},{"cell_type":"code","source":"X_trains_df=pd.DataFrame(x_train,columns=x_train.columns)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:55.288909Z","iopub.execute_input":"2023-03-28T12:20:55.289695Z","iopub.status.idle":"2023-03-28T12:20:55.294982Z","shell.execute_reply.started":"2023-03-28T12:20:55.289658Z","shell.execute_reply":"2023-03-28T12:20:55.294139Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:55.296488Z","iopub.execute_input":"2023-03-28T12:20:55.297934Z","iopub.status.idle":"2023-03-28T12:20:55.313875Z","shell.execute_reply.started":"2023-03-28T12:20:55.297876Z","shell.execute_reply":"2023-03-28T12:20:55.312321Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   Survival_binary\n0                0\n1                0\n2                0\n3                0\n4                1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survival_binary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(X_trains_df.isnull().sum())\nprint(X_trains_df.isin([np.nan, np.inf, -np.inf]).sum().sum())\n\nprint(pd.isnull(y_train).sum())\nprint(y_train.isin([np.nan, np.inf, -np.inf]).sum().sum())","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:55.315479Z","iopub.execute_input":"2023-03-28T12:20:55.316511Z","iopub.status.idle":"2023-03-28T12:20:55.355296Z","shell.execute_reply.started":"2023-03-28T12:20:55.316465Z","shell.execute_reply":"2023-03-28T12:20:55.354000Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"AlexNet_Avg_F0      0\nAlexNet_Avg_F1      0\nAlexNet_Avg_F2      0\nAlexNet_Avg_F3      0\nAlexNet_Avg_F4      0\n                   ..\nAlexNet_Std_F240    0\nAlexNet_Std_F248    0\nAlexNet_Std_F249    0\nAlexNet_Std_F251    0\nAlexNet_Std_F253    0\nLength: 342, dtype: int64\n0\nSurvival_binary    0\ndtype: int64\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"X_trains_df = X_trains_df.fillna(X_trains_df.mean())","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:55.356962Z","iopub.execute_input":"2023-03-28T12:20:55.357656Z","iopub.status.idle":"2023-03-28T12:20:55.432988Z","shell.execute_reply.started":"2023-03-28T12:20:55.357611Z","shell.execute_reply":"2023-03-28T12:20:55.431715Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(X_trains_df.isnull().sum())\nprint(X_trains_df.isin([np.nan, np.inf, -np.inf]).sum().sum())\n\nprint(pd.isnull(y_train).sum())\nprint(y_train.isin([np.nan, np.inf, -np.inf]).sum().sum())","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:55.434410Z","iopub.execute_input":"2023-03-28T12:20:55.434858Z","iopub.status.idle":"2023-03-28T12:20:55.471418Z","shell.execute_reply.started":"2023-03-28T12:20:55.434815Z","shell.execute_reply":"2023-03-28T12:20:55.470076Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"AlexNet_Avg_F0      0\nAlexNet_Avg_F1      0\nAlexNet_Avg_F2      0\nAlexNet_Avg_F3      0\nAlexNet_Avg_F4      0\n                   ..\nAlexNet_Std_F240    0\nAlexNet_Std_F248    0\nAlexNet_Std_F249    0\nAlexNet_Std_F251    0\nAlexNet_Std_F253    0\nLength: 342, dtype: int64\n0\nSurvival_binary    0\ndtype: int64\n0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **SVM Feature Selection**","metadata":{}},{"cell_type":"code","source":"# dtc = tree.DecisionTreeClassifier()\n\nsvm = SVC(kernel=\"linear\")\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:55.472832Z","iopub.execute_input":"2023-03-28T12:20:55.473141Z","iopub.status.idle":"2023-03-28T12:20:55.478525Z","shell.execute_reply.started":"2023-03-28T12:20:55.473113Z","shell.execute_reply":"2023-03-28T12:20:55.477276Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"svm_selector_model = RFE(estimator=svm,n_features_to_select=120)\nsvm_selector_model_fit=svm_selector_model.fit(X_trains_df,y_train.values.ravel())\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:20:55.479909Z","iopub.execute_input":"2023-03-28T12:20:55.480307Z","iopub.status.idle":"2023-03-28T12:43:40.133051Z","shell.execute_reply.started":"2023-03-28T12:20:55.480274Z","shell.execute_reply":"2023-03-28T12:43:40.131802Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"feat_index = pd.Series(data = svm_selector_model_fit.ranking_, index = x_train.columns)\nsigni_feat_rfe = feat_index[feat_index==1].index\nprint('Significant features from RFE using SVM',signi_feat_rfe)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:43:40.134560Z","iopub.execute_input":"2023-03-28T12:43:40.135101Z","iopub.status.idle":"2023-03-28T12:43:40.142370Z","shell.execute_reply.started":"2023-03-28T12:43:40.135067Z","shell.execute_reply":"2023-03-28T12:43:40.140887Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Significant features from RFE using SVM Index(['AlexNet_Avg_F1', 'AlexNet_Avg_F3', 'AlexNet_Avg_F6', 'AlexNet_Avg_F8',\n       'AlexNet_Avg_F11', 'AlexNet_Avg_F12', 'AlexNet_Avg_F18',\n       'AlexNet_Avg_F19', 'AlexNet_Avg_F22', 'AlexNet_Avg_F23',\n       ...\n       'AlexNet_Std_F88', 'AlexNet_Std_F100', 'AlexNet_Std_F126',\n       'AlexNet_Std_F129', 'AlexNet_Std_F132', 'AlexNet_Std_F143',\n       'AlexNet_Std_F152', 'AlexNet_Std_F156', 'AlexNet_Std_F183',\n       'AlexNet_Std_F237'],\n      dtype='object', length=120)\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Original number of features present in the dataset : {}'.format(x_train.shape[1]))\nprint('Number of features selected by SVM using Recursive feature selection is : {}'.format(len(signi_feat_rfe)))","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:43:40.143884Z","iopub.execute_input":"2023-03-28T12:43:40.144208Z","iopub.status.idle":"2023-03-28T12:43:40.156356Z","shell.execute_reply.started":"2023-03-28T12:43:40.144179Z","shell.execute_reply":"2023-03-28T12:43:40.155321Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Original number of features present in the dataset : 342\nNumber of features selected by SVM using Recursive feature selection is : 120\n","output_type":"stream"}]},{"cell_type":"code","source":"df_selected_features = x_train.filter(items=signi_feat_rfe, axis=1)\ndf_selected_features_test = x_train_test.filter(items=signi_feat_rfe, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:43:40.157806Z","iopub.execute_input":"2023-03-28T12:43:40.158851Z","iopub.status.idle":"2023-03-28T12:43:40.169653Z","shell.execute_reply.started":"2023-03-28T12:43:40.158804Z","shell.execute_reply":"2023-03-28T12:43:40.168621Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df_selected_features.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:43:40.171128Z","iopub.execute_input":"2023-03-28T12:43:40.171778Z","iopub.status.idle":"2023-03-28T12:43:40.206433Z","shell.execute_reply.started":"2023-03-28T12:43:40.171740Z","shell.execute_reply":"2023-03-28T12:43:40.205209Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"   AlexNet_Avg_F1  AlexNet_Avg_F3  AlexNet_Avg_F6  AlexNet_Avg_F8  \\\n0       -0.230860       -0.448268        0.451090       -0.760153   \n1       -0.253034       -0.795182        0.697259       -0.195385   \n2       -0.340875       -0.517723        2.983567        2.507372   \n3       -0.617266        0.266700        1.677595       -0.109706   \n4       -0.626424       -0.697612        0.155343       -0.830755   \n\n   AlexNet_Avg_F11  AlexNet_Avg_F12  AlexNet_Avg_F18  AlexNet_Avg_F19  \\\n0        -0.617392         0.145388        -0.713352         3.072294   \n1        -0.166722        -0.300179        -0.610645         1.006501   \n2        -0.315714         1.890868        -0.603130         0.804748   \n3        -0.592379        -0.929081        -0.664520         1.748768   \n4         0.427962        -0.564038        -0.113874         0.836717   \n\n   AlexNet_Avg_F22  AlexNet_Avg_F23  ...  AlexNet_Std_F88  AlexNet_Std_F100  \\\n0        -3.343893         0.287640  ...        -0.395601         -0.518436   \n1        -1.709687         0.445418  ...        -0.273571         -0.730792   \n2        -0.773580         0.722606  ...         0.586920          3.010638   \n3        -1.306905         0.013670  ...        -0.270282         -0.054897   \n4        -0.042087         0.700451  ...        -0.016216          0.019415   \n\n   AlexNet_Std_F126  AlexNet_Std_F129  AlexNet_Std_F132  AlexNet_Std_F143  \\\n0          1.409486          1.172180          0.300286          1.664165   \n1          2.158627          1.716598          3.220307          1.408198   \n2          2.156915          0.932539          1.039452          2.013338   \n3          1.176164          1.144551          0.431733          1.598507   \n4          0.295968          0.456092          1.261358          0.109802   \n\n   AlexNet_Std_F152  AlexNet_Std_F156  AlexNet_Std_F183  AlexNet_Std_F237  \n0          0.429515          2.372739          0.392264          0.039178  \n1         -0.042710         -0.806777          0.474495         -0.647180  \n2          0.366237          1.555614          0.634674          0.464683  \n3          0.366779          0.675432         -0.155681         -0.532264  \n4         -0.937823         -0.785477         -0.283774         -0.586898  \n\n[5 rows x 120 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AlexNet_Avg_F1</th>\n      <th>AlexNet_Avg_F3</th>\n      <th>AlexNet_Avg_F6</th>\n      <th>AlexNet_Avg_F8</th>\n      <th>AlexNet_Avg_F11</th>\n      <th>AlexNet_Avg_F12</th>\n      <th>AlexNet_Avg_F18</th>\n      <th>AlexNet_Avg_F19</th>\n      <th>AlexNet_Avg_F22</th>\n      <th>AlexNet_Avg_F23</th>\n      <th>...</th>\n      <th>AlexNet_Std_F88</th>\n      <th>AlexNet_Std_F100</th>\n      <th>AlexNet_Std_F126</th>\n      <th>AlexNet_Std_F129</th>\n      <th>AlexNet_Std_F132</th>\n      <th>AlexNet_Std_F143</th>\n      <th>AlexNet_Std_F152</th>\n      <th>AlexNet_Std_F156</th>\n      <th>AlexNet_Std_F183</th>\n      <th>AlexNet_Std_F237</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.230860</td>\n      <td>-0.448268</td>\n      <td>0.451090</td>\n      <td>-0.760153</td>\n      <td>-0.617392</td>\n      <td>0.145388</td>\n      <td>-0.713352</td>\n      <td>3.072294</td>\n      <td>-3.343893</td>\n      <td>0.287640</td>\n      <td>...</td>\n      <td>-0.395601</td>\n      <td>-0.518436</td>\n      <td>1.409486</td>\n      <td>1.172180</td>\n      <td>0.300286</td>\n      <td>1.664165</td>\n      <td>0.429515</td>\n      <td>2.372739</td>\n      <td>0.392264</td>\n      <td>0.039178</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.253034</td>\n      <td>-0.795182</td>\n      <td>0.697259</td>\n      <td>-0.195385</td>\n      <td>-0.166722</td>\n      <td>-0.300179</td>\n      <td>-0.610645</td>\n      <td>1.006501</td>\n      <td>-1.709687</td>\n      <td>0.445418</td>\n      <td>...</td>\n      <td>-0.273571</td>\n      <td>-0.730792</td>\n      <td>2.158627</td>\n      <td>1.716598</td>\n      <td>3.220307</td>\n      <td>1.408198</td>\n      <td>-0.042710</td>\n      <td>-0.806777</td>\n      <td>0.474495</td>\n      <td>-0.647180</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.340875</td>\n      <td>-0.517723</td>\n      <td>2.983567</td>\n      <td>2.507372</td>\n      <td>-0.315714</td>\n      <td>1.890868</td>\n      <td>-0.603130</td>\n      <td>0.804748</td>\n      <td>-0.773580</td>\n      <td>0.722606</td>\n      <td>...</td>\n      <td>0.586920</td>\n      <td>3.010638</td>\n      <td>2.156915</td>\n      <td>0.932539</td>\n      <td>1.039452</td>\n      <td>2.013338</td>\n      <td>0.366237</td>\n      <td>1.555614</td>\n      <td>0.634674</td>\n      <td>0.464683</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.617266</td>\n      <td>0.266700</td>\n      <td>1.677595</td>\n      <td>-0.109706</td>\n      <td>-0.592379</td>\n      <td>-0.929081</td>\n      <td>-0.664520</td>\n      <td>1.748768</td>\n      <td>-1.306905</td>\n      <td>0.013670</td>\n      <td>...</td>\n      <td>-0.270282</td>\n      <td>-0.054897</td>\n      <td>1.176164</td>\n      <td>1.144551</td>\n      <td>0.431733</td>\n      <td>1.598507</td>\n      <td>0.366779</td>\n      <td>0.675432</td>\n      <td>-0.155681</td>\n      <td>-0.532264</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.626424</td>\n      <td>-0.697612</td>\n      <td>0.155343</td>\n      <td>-0.830755</td>\n      <td>0.427962</td>\n      <td>-0.564038</td>\n      <td>-0.113874</td>\n      <td>0.836717</td>\n      <td>-0.042087</td>\n      <td>0.700451</td>\n      <td>...</td>\n      <td>-0.016216</td>\n      <td>0.019415</td>\n      <td>0.295968</td>\n      <td>0.456092</td>\n      <td>1.261358</td>\n      <td>0.109802</td>\n      <td>-0.937823</td>\n      <td>-0.785477</td>\n      <td>-0.283774</td>\n      <td>-0.586898</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 120 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_selected_features.to_csv('SelectedFeaturesVGGFinalOS.csv',index = None,header = df_selected_features.columns)\ndf_selected_features_test.to_csv('SelectedFeaturesVGGFinalTESTOS.csv',index = None,header = df_selected_features_test.columns)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:43:40.207834Z","iopub.execute_input":"2023-03-28T12:43:40.208175Z","iopub.status.idle":"2023-03-28T12:43:40.567007Z","shell.execute_reply.started":"2023-03-28T12:43:40.208144Z","shell.execute_reply":"2023-03-28T12:43:40.565808Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# skip NN 21 March\ncolumns = ['VGG_F' + str(i) for i in range(df_selected_features.shape[1])]\ndf_selected_features.to_csv('SelectedFeaturesVGGFinalMergedOS.csv',index = None,header = columns)\n\ncolumns = ['VGG_F' + str(i) for i in range(df_selected_features_test.shape[1])]\ndf_selected_features_test.to_csv('SelectedFeaturesVGGFinalMergedTESTOS.csv',index = None,header = columns)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:43:40.568611Z","iopub.execute_input":"2023-03-28T12:43:40.568973Z","iopub.status.idle":"2023-03-28T12:43:40.910076Z","shell.execute_reply.started":"2023-03-28T12:43:40.568940Z","shell.execute_reply":"2023-03-28T12:43:40.908863Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df_selected_features_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:43:40.911432Z","iopub.execute_input":"2023-03-28T12:43:40.911755Z","iopub.status.idle":"2023-03-28T12:43:40.919499Z","shell.execute_reply.started":"2023-03-28T12:43:40.911726Z","shell.execute_reply":"2023-03-28T12:43:40.918024Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(200, 120)"},"metadata":{}}]},{"cell_type":"code","source":"# Step 6: Train an SVM model using Stratified Kfold cross validation and grid search cv\nscaler = StandardScaler()\nsvc = SVC(probability=True)\nparam_grid = {\n    'C': [0.1, 1, 10],\n    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n    'gamma': ['scale', 'auto']\n}\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nmean_fpr = np.linspace(0, 1, 100)\ntprs = []\naucs = []\nbest_svc = None\nbest_score = 0\n\nfor i, (train, test) in enumerate(cv.split(df_selected_features, y)):\n    X_train = df_selected_features.iloc[train]\n    y_train = y.iloc[train].values.ravel()\n    X_test = df_selected_features.iloc[test]\n    y_test = y.iloc[test].values.ravel()\n    \n#     common_indices = set(train).intersection(set(test))\n#     print('Common indices:', common_indices if common_indices else None)\n\n    grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=cv, scoring='roc_auc')\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.fit_transform(X_test)\n    grid_search.fit(X_train_scaled, y_train)\n    best_svc_fold = grid_search.best_estimator_\n    \n    score = grid_search.best_score_\n    if score > best_score:\n        best_score = score\n        best_svc = grid_search.best_estimator_\n    \n    y_score = best_svc_fold.predict_proba(X_test_scaled)[:, 1]\n    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n    tprs.append(np.interp(mean_fpr, fpr, tpr))\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    print('Fold %d ROC AUC: %.4f' % (i+1, roc_auc))\n\n\nplt.figure(figsize=(8,6))\nfor i in range(len(tprs)):\n    plt.plot(mean_fpr, tprs[i], lw=2, alpha=0.6, label='ROC fold %d (AUC = %0.2f)' % (i+1, aucs[i]))\n\nplt.plot([0,1],[0,1],'--',lw=2, color='black')\nmean_tpr = np.mean(tprs, axis=0)\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nplt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),lw=2, alpha=.8)\n\n# plt.fill_between(mean_fpr, mean_tpr - std_auc, mean_tpr + std_auc, alpha=.2, color='b')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.savefig('auc_roc.png')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, plot_roc_curve\n\n# Predict on test data\ny_pred = best_svc.predict(df_selected_features_test)\n\n# Print classification report\nprint(classification_report(y_train_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}